[trainer]
batch_size = 512
gamma = 0.95
tau = 0.005
lr_actor  = 0.0001     ; ↓ 后期更稳
lr_critic = 0.0001
lr_alpha  = 0.0001
bc_ratio  = 0.5        ; ↓ 让 RL 更主导
lambda_bc = 0.5

[imitation_learning]
il_episodes = 1000
il_policy = orca
il_epochs = 2000
il_learning_rate = 0.0003
safety_space = 0.10

[train]
train_batches = 120     ; ↑ 每轮更新更充分
train_episodes = 1500
sample_episodes = 24    ; ↑ 略多采样，减方差
target_update_interval = 50
evaluation_interval = 100
capacity = 100000
epsilon_start = 0.1
epsilon_end = 0.05
epsilon_decay = 2000
checkpoint_interval = 500

[dagger]
exp_full = 100
exp_anneal = 300       ; ↓ 更快结束整集专家
min_prob = 0.0         ; 尾部完全交给 RL

