[action_space]
kinematics = holonomic
speed_samples = 5
rotation_samples = 16
sampling = exponential
query_env = true
time_step = 0.25

[mamba]
use_amp = true
try_compile = true
obs_dim        = 34
state_dim      = 34
robot_feat_dim = 9
human_feat_dim = 5
human_num      = 5
hidden_dim     = 64
n_blocks       = 4
conv_dim       = 4
expand         = 2
dropout        = 0.1
gamma          = 0.95
action_scale   = 1.0
multiagent_training = true
learning_rate  = 0.0003  ; 兼容字段，不被新训练器使用

; 其余旧策略段保留以兼容（未使用可忽略）
[rl]
gamma = 0.95
learning_rate = 0.001

[om]
cell_num = 4
cell_size = 1
om_channel_size = 3

[cadrl]
mlp_dims = 150, 100, 100, 1
multiagent_training = false

[lstm_rl]
global_state_dim = 50
mlp1_dims = 150, 100, 100, 50
mlp2_dims = 150, 100, 100, 1
multiagent_training = true
with_om = false
with_interaction_module = false

[srl]
mlp1_dims = 150, 100, 100, 50
mlp2_dims = 150, 100, 100, 1
multiagent_training = true
with_om = false

[sarl]
mlp1_dims = 150
mlp2_dims = 100
attention_dims = 100, 100, 1
mlp3_dims = 150, 100, 100, 1
multiagent_training = true
with_om = false
with_global_state = true
hidden_dim = 150

